{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos de estaciones desde el 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datos/RMCAB/Clean/Sec_Cruzada_RMCAB.csv\")\n",
    "df[\"Fecha_Hora\"] = pd.to_datetime(df[\"Fecha_Hora\"])\n",
    "\n",
    "estaciones = df[\"Estación\"].unique().tolist()\n",
    "info_estaciones = pd.DataFrame(columns=[\"Estación\", \"Min_Fecha_Hora\"])\n",
    "\n",
    "# Iterate over each station and find the minimum date and time\n",
    "for estacion in estaciones:\n",
    "    min_date = df[df[\"Estación\"] == estacion][\"Fecha_Hora\"].min()\n",
    "    new_row = pd.DataFrame({\"Estación\": [estacion], \"Min_Fecha_Hora\": [min_date]})\n",
    "    info_estaciones = pd.concat([info_estaciones, new_row], ignore_index=True)\n",
    "\n",
    "estaciones_filtradas = info_estaciones.head(7)[\"Estación\"].tolist()\n",
    "\n",
    "df = df[df[\"Estación\"].isin(estaciones_filtradas)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputación para cada variable por estación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carvajal - Sevillana',\n",
       " 'Guaymaral',\n",
       " 'MinAmbiente',\n",
       " 'Puente Aranda',\n",
       " 'Suba',\n",
       " 'Usaquen',\n",
       " 'Las Ferias']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estaciones_filtradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estación                0\n",
       "BBP                204769\n",
       "BC ug/m3           204769\n",
       "CO                 177160\n",
       "Dir Viento         204769\n",
       "Dir Viento 10M          0\n",
       "HR                      0\n",
       "HR_2m              204769\n",
       "Humedad Inter      204769\n",
       "NO                  95016\n",
       "NO2                 95053\n",
       "NOX                  7068\n",
       "OZONO               64576\n",
       "OZONO Envea        204769\n",
       "PM10                 7099\n",
       "PM2.5              109894\n",
       "Precipitacion           0\n",
       "Presion Baro            0\n",
       "Rad Solar               0\n",
       "SO2                201165\n",
       "SO2 Envea          204769\n",
       "Temp_4m            204769\n",
       "Tempe Inter        204769\n",
       "Temperatura         62306\n",
       "Temperatura 20M     62306\n",
       "Temperatura 8M      62306\n",
       "UV-BC              204769\n",
       "Vel Viento         204769\n",
       "Vel Viento 10M          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombre_estacion = \"Guaymaral\"\n",
    "\n",
    "e = df[df[\"Estación\"] == nombre_estacion]\n",
    "del df\n",
    "#e = pd.read_csv(f\"../Datos/RMCAB/Clean/Datos_sin_faltantes/{nombre_estacion}_imputado.csv\")\n",
    "e = e.set_index(\"Fecha_Hora\")\n",
    "var_to_imput = e.columns[1:].tolist()\n",
    "e.isna().sum()\n",
    "\n",
    "try:\n",
    "    e = pd.read_csv(f\"../Datos/RMCAB/Clean/Datos_sin_faltantes/{nombre_estacion}_imputado.csv\")\n",
    "except:\n",
    "    e.to_csv(f\"../Datos/RMCAB/Clean/Datos_sin_faltantes/{nombre_estacion}_imputado.csv\")\n",
    "    print(\"No se encontró el archivo, se creó uno nuevo\")\n",
    "e = e.set_index(\"Fecha_Hora\")\n",
    "e.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La disponibilidad de datos para BBP es insuficiente para imputar\n",
      "La disponibilidad de datos para BC ug/m3 es insuficiente para imputar\n",
      "La disponibilidad de datos para CO es insuficiente para imputar\n",
      "La disponibilidad de datos para Dir Viento es insuficiente para imputar\n",
      "La disponibilidad de datos para HR_2m es insuficiente para imputar\n",
      "La disponibilidad de datos para Humedad Inter es insuficiente para imputar\n",
      "La disponibilidad de datos para NO es insuficiente para imputar\n",
      "La disponibilidad de datos para NO2 es insuficiente para imputar\n",
      "La disponibilidad de datos para OZONO Envea es insuficiente para imputar\n",
      "La disponibilidad de datos para PM2.5 es insuficiente para imputar\n",
      "La disponibilidad de datos para SO2 es insuficiente para imputar\n",
      "La disponibilidad de datos para SO2 Envea es insuficiente para imputar\n",
      "La disponibilidad de datos para Temp_4m es insuficiente para imputar\n",
      "La disponibilidad de datos para Tempe Inter es insuficiente para imputar\n",
      "La disponibilidad de datos para UV-BC es insuficiente para imputar\n",
      "La disponibilidad de datos para Vel Viento es insuficiente para imputar\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre cada variable a imputar\n",
    "for var in var_to_imput:\n",
    "    disp = 1 - (e[var].isna().sum() / len(e[var]))  # Calcular la disponibilidad de datos\n",
    "    #print(var, disp, len(e[var]))\n",
    "    # Imputar solo si la disponibilidad de datos es suficiente\n",
    "    if disp >= 0.6: \n",
    "\n",
    "        e = pd.read_csv(f\"../Datos/RMCAB/Clean/Datos_sin_faltantes/{nombre_estacion}_imputado.csv\")   \n",
    "        e = e.set_index(\"Fecha_Hora\")\n",
    "        min_date = e[var].dropna().index.min()\n",
    "        df_to_replace = e[var].loc[e[var].index >= min_date]\n",
    "        df_to_replace = pd.DataFrame(df_to_replace)\n",
    "        #print(df_to_replace)\n",
    "        n_lags = 50\n",
    "        correlations = [e[var].autocorr(lag) for lag in range(1, n_lags+1)]\n",
    "        correlation_df = pd.DataFrame({'Lag': range(1, n_lags+1), 'Correlation': correlations})\n",
    "        top_lags = correlation_df.sort_values(by='Correlation', ascending=False)\n",
    "        best_lags = top_lags.head(5)[\"Lag\"].tolist()\n",
    "        \n",
    "        imputed_count = 0  # Contador de valores imputados\n",
    "\n",
    "        # Imputar los valores nulos uno a uno\n",
    "        while df_to_replace[var].isna().sum() > 0:\n",
    "            next_nan_value_date = df_to_replace[df_to_replace.isna().any(axis=1)].index[0]\n",
    "            \n",
    "            model_df = df_to_replace.loc[df_to_replace.index <= next_nan_value_date]\n",
    "            model_df = pd.DataFrame(model_df)\n",
    "\n",
    "            # Crear variables de lag\n",
    "            for lag in best_lags:\n",
    "                model_df[f'lag_{lag}'] = model_df[var].shift(lag)\n",
    "\n",
    "            next_nan_value = model_df.tail(1)\n",
    "            model_df = model_df.dropna()\n",
    "\n",
    "            # Preparar los datos de entrenamiento\n",
    "            X = model_df.drop(columns=[var])\n",
    "            y = model_df[var]\n",
    "\n",
    "            # Reentrenar el modelo cada 100 imputaciones\n",
    "            if imputed_count % 100 == 0 or imputed_count == 0:\n",
    "                model = XGBRegressor()\n",
    "                model.fit(X, y)\n",
    "                #print(f\"Modelo reentrenado en la imputación {imputed_count}\")\n",
    "\n",
    "            # Predecir el siguiente valor nulo y actualizar el DataFrame\n",
    "            y_pred = model.predict(next_nan_value.drop(columns=var))\n",
    "            e[var].loc[next_nan_value_date] = y_pred.round(0)\n",
    "            df_to_replace[var].loc[next_nan_value_date] = y_pred.round(0)\n",
    "\n",
    "            imputed_count += 1  # Actualizar el contador\n",
    "            #print(f\"Imputación realizada en {next_nan_value_date}: {y_pred.round(0)}\")\n",
    "    if disp < 0.6:\n",
    "        print(f\"La disponibilidad de datos para {var} es insuficiente para imputar\")\n",
    "    e.to_csv(f\"../Datos/RMCAB/Clean/Datos_sin_faltantes/{nombre_estacion}_imputado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estación                0\n",
       "BBP                204769\n",
       "BC ug/m3           204769\n",
       "CO                 177160\n",
       "Dir Viento         204769\n",
       "Dir Viento 10M          0\n",
       "HR                      0\n",
       "HR_2m              204769\n",
       "Humedad Inter      204769\n",
       "NO                  95016\n",
       "NO2                 95053\n",
       "NOX                  7068\n",
       "OZONO               64576\n",
       "OZONO Envea        204769\n",
       "PM10                 7099\n",
       "PM2.5              109894\n",
       "Precipitacion           0\n",
       "Presion Baro            0\n",
       "Rad Solar               0\n",
       "SO2                201165\n",
       "SO2 Envea          204769\n",
       "Temp_4m            204769\n",
       "Tempe Inter        204769\n",
       "Temperatura         62306\n",
       "Temperatura 20M     62306\n",
       "Temperatura 8M      62306\n",
       "UV-BC              204769\n",
       "Vel Viento         204769\n",
       "Vel Viento 10M          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
